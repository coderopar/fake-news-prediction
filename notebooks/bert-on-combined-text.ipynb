{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13217692,"sourceType":"datasetVersion","datasetId":8377929}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BERT Model on Combined Text.\n\nIn this section, we are applying **BERT (Bidirectional Encoder Representations from Transformers)** to predict whether a given news article is *fake* or *true*.  \n\n### Why BERT?\n- BERT is a **transformer-based model** that has been pre-trained on massive amounts of text.  \n- It understands **context in both directions** (left and right of a word), which makes it powerful for language understanding tasks.  \n- For text classification tasks like **fake news detection**, BERT has shown state-of-the-art performance compared to traditional machine learning methods.  \n\n### Workflow\nWe will follow these steps in our modeling pipeline:\n\n1. **Install dependencies** – Set up HuggingFace Transformers, PyTorch, and Scikit-learn.  \n2. **Load data** – Import the prepared train, validation, and test CSVs.  \n3. **Explore data** – Check dataset shape, column names, and class balance.  \n4. **Preprocess & tokenize** – Convert raw text into tokens using the bert-base-uncased tokenizer.  \n5. **Create PyTorch dataset loaders** – Wrap the tokenized inputs and labels into PyTorch Dataset and DataLoader objects for training.  \n6. **Model setup** – Load BertForSequenceClassification with two labels (fake vs true).  \n7. **Training loop** – Train BERT with AdamW optimizer, scheduler, and backpropagation.  \n8. **Evaluation** – Measure accuracy, precision, recall, and F1 score on validation and test data.  \n9. **Save the model** – Store the trained model and tokenizer for future use.\n\nBy the end of this workflow, we will have a fine-tuned BERT model that can classify unseen news articles as either fake or true.\n","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Installing dependencies.","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets torch scikit-learn -q\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:37:38.601164Z","iopub.execute_input":"2025-10-01T05:37:38.601772Z","iopub.status.idle":"2025-10-01T05:38:53.802875Z","shell.execute_reply.started":"2025-10-01T05:37:38.601745Z","shell.execute_reply":"2025-10-01T05:38:53.802206Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW  \nfrom transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:38:53.804290Z","iopub.execute_input":"2025-10-01T05:38:53.804625Z","iopub.status.idle":"2025-10-01T05:39:18.239923Z","shell.execute_reply.started":"2025-10-01T05:38:53.804601Z","shell.execute_reply":"2025-10-01T05:39:18.239301Z"}},"outputs":[{"name":"stderr","text":"2025-10-01 05:39:06.424872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759297146.596927      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759297146.647550      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Step 2: Loading data.","metadata":{}},{"cell_type":"markdown","source":"We now load the training, validation, and test datasets\n\n- train.csv: Used for fitting the BERT model parameters.\n- val.csv: Used during training to monitor model performance and tune hyperparameters.\n- test.csv: Held out until the final stage to evaluate the model on completely unseen data.","metadata":{}},{"cell_type":"code","source":"# Load the prepared datasets\ntrain_df = pd.read_csv(\"/kaggle/input/modelling-data/Modelling Data/train.csv\")\nval_df   = pd.read_csv(\"/kaggle/input/modelling-data/Modelling Data/val.csv\")\ntest_df  = pd.read_csv(\"/kaggle/input/modelling-data/Modelling Data/test.csv\")\n\n# Check dataset shapes\nprint(\"Train shape:\", train_df.shape)\nprint(\"Validation shape:\", val_df.shape)\nprint(\"Test shape:\", test_df.shape)\n\n# Glimpse of training data\ntrain_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:39:18.240669Z","iopub.execute_input":"2025-10-01T05:39:18.241190Z","iopub.status.idle":"2025-10-01T05:39:24.399877Z","shell.execute_reply.started":"2025-10-01T05:39:18.241170Z","shell.execute_reply":"2025-10-01T05:39:24.399133Z"}},"outputs":[{"name":"stdout","text":"Train shape: (35918, 10)\nValidation shape: (4490, 10)\nTest shape: (4490, 10)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               title  \\\n0  UPDATE: BUSTED By The Secret Service…CNN’s Apr...   \n1  THE LEFT LOSES AGAIN: Third Quarter Economic E...   \n2   Trump’s Own Staff Thinks He’s A Joke, Laughs ...   \n3  Seoul considers unilateral sanctions against N...   \n4   Democrats Offer Bill That Would FORCE Trump T...   \n\n                                                text          subject  \\\n0  The Secret Service pushed back on a CNN report...        left-news   \n1  The news that the forecast for the third quart...  Government News   \n2  As the Russian investigation is getting uncomf...             News   \n3  SEOUL (Reuters) - South Korea is considering l...        worldnews   \n4  The vast majority of Donald Trump s campaign p...             News   \n\n                date label                                        title_clean  \\\n0       Dec 13, 2017  FAKE  update busted secret service cnn april ryan ca...   \n1       Aug 19, 2017  FAKE  left loses third quarter economic estimate exp...   \n2      June 12, 2017  FAKE     trump staff think joke laugh july th ultimatum   \n3  October 18, 2017   TRUE    seoul considers unilateral sanction north korea   \n4     March 24, 2017  FAKE  democrat offer bill would force trump keep one...   \n\n                                          text_clean  \\\n0  secret service pushed back cnn reporter claim ...   \n1  news forecast third quarter gdp set expand bad...   \n2  russian investigation getting uncomfortably cl...   \n3  seoul reuters south korea considering levying ...   \n4  vast majority donald trump campaign promise un...   \n\n                                       combined_text  _char_len  _tok_len_ws  \n0  update busted secret service cnn april ryan ca...       1260          180  \n1  left loses third quarter economic estimate exp...       1166          162  \n2  trump staff think joke laugh july th ultimatum...       1587          227  \n3  seoul considers unilateral sanction north kore...        390           55  \n4  democrat offer bill would force trump keep one...       1962          266  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>label</th>\n      <th>title_clean</th>\n      <th>text_clean</th>\n      <th>combined_text</th>\n      <th>_char_len</th>\n      <th>_tok_len_ws</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>UPDATE: BUSTED By The Secret Service…CNN’s Apr...</td>\n      <td>The Secret Service pushed back on a CNN report...</td>\n      <td>left-news</td>\n      <td>Dec 13, 2017</td>\n      <td>FAKE</td>\n      <td>update busted secret service cnn april ryan ca...</td>\n      <td>secret service pushed back cnn reporter claim ...</td>\n      <td>update busted secret service cnn april ryan ca...</td>\n      <td>1260</td>\n      <td>180</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>THE LEFT LOSES AGAIN: Third Quarter Economic E...</td>\n      <td>The news that the forecast for the third quart...</td>\n      <td>Government News</td>\n      <td>Aug 19, 2017</td>\n      <td>FAKE</td>\n      <td>left loses third quarter economic estimate exp...</td>\n      <td>news forecast third quarter gdp set expand bad...</td>\n      <td>left loses third quarter economic estimate exp...</td>\n      <td>1166</td>\n      <td>162</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Trump’s Own Staff Thinks He’s A Joke, Laughs ...</td>\n      <td>As the Russian investigation is getting uncomf...</td>\n      <td>News</td>\n      <td>June 12, 2017</td>\n      <td>FAKE</td>\n      <td>trump staff think joke laugh july th ultimatum</td>\n      <td>russian investigation getting uncomfortably cl...</td>\n      <td>trump staff think joke laugh july th ultimatum...</td>\n      <td>1587</td>\n      <td>227</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Seoul considers unilateral sanctions against N...</td>\n      <td>SEOUL (Reuters) - South Korea is considering l...</td>\n      <td>worldnews</td>\n      <td>October 18, 2017</td>\n      <td>TRUE</td>\n      <td>seoul considers unilateral sanction north korea</td>\n      <td>seoul reuters south korea considering levying ...</td>\n      <td>seoul considers unilateral sanction north kore...</td>\n      <td>390</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Democrats Offer Bill That Would FORCE Trump T...</td>\n      <td>The vast majority of Donald Trump s campaign p...</td>\n      <td>News</td>\n      <td>March 24, 2017</td>\n      <td>FAKE</td>\n      <td>democrat offer bill would force trump keep one...</td>\n      <td>vast majority donald trump campaign promise un...</td>\n      <td>democrat offer bill would force trump keep one...</td>\n      <td>1962</td>\n      <td>266</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Step 3: Explore the Data.","metadata":{}},{"cell_type":"code","source":"# Check unique labels\nprint(\"Unique labels:\", train_df['label'].unique())\n\n# Convert labels to numeric (FAKE=0, TRUE=1)\nlabel_mapping = {\"FAKE\": 0, \"TRUE\": 1}\ntrain_df['label_num'] = train_df['label'].map(label_mapping)\nval_df['label_num']   = val_df['label'].map(label_mapping)\ntest_df['label_num']  = test_df['label'].map(label_mapping)\n\n# Check distribution of classes\nprint(\"Training label distribution:\\n\", train_df['label_num'].value_counts(normalize=True))\nprint(\"Validation label distribution:\\n\", val_df['label_num'].value_counts(normalize=True))\nprint(\"Test label distribution:\\n\", test_df['label_num'].value_counts(normalize=True))\n\n# sneak peek after conversion\ntrain_df[['combined_text', 'label', 'label_num']].head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:39:24.401401Z","iopub.execute_input":"2025-10-01T05:39:24.401623Z","iopub.status.idle":"2025-10-01T05:39:24.434683Z","shell.execute_reply.started":"2025-10-01T05:39:24.401605Z","shell.execute_reply":"2025-10-01T05:39:24.434131Z"}},"outputs":[{"name":"stdout","text":"Unique labels: ['FAKE' 'TRUE']\nTraining label distribution:\n label_num\n0    0.522997\n1    0.477003\nName: proportion, dtype: float64\nValidation label distribution:\n label_num\n0    0.52294\n1    0.47706\nName: proportion, dtype: float64\nTest label distribution:\n label_num\n0    0.52294\n1    0.47706\nName: proportion, dtype: float64\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                       combined_text label  label_num\n0  update busted secret service cnn april ryan ca...  FAKE          0\n1  left loses third quarter economic estimate exp...  FAKE          0\n2  trump staff think joke laugh july th ultimatum...  FAKE          0\n3  seoul considers unilateral sanction north kore...  TRUE          1\n4  democrat offer bill would force trump keep one...  FAKE          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>combined_text</th>\n      <th>label</th>\n      <th>label_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>update busted secret service cnn april ryan ca...</td>\n      <td>FAKE</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>left loses third quarter economic estimate exp...</td>\n      <td>FAKE</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>trump staff think joke laugh july th ultimatum...</td>\n      <td>FAKE</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>seoul considers unilateral sanction north kore...</td>\n      <td>TRUE</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>democrat offer bill would force trump keep one...</td>\n      <td>FAKE</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Step 4: Define Parameters.","metadata":{}},{"cell_type":"markdown","source":"### Setting Parameters\n\nAt this stage, after inspecting the dataset, we define all key parameters in one dictionary (PARAMS):\n\n  **model_name**: the pre-trained model to load (bert-base-uncased is common for English).  \n  **max_len**: maximum token length for each sequence. This controls how long inputs are padded/truncated during tokenization.  \n  **batch_size**: number of samples per batch for training.  \n  **learning_rate**: optimizer learning rate (2e-5 is a typical starting point for BERT).  \n  **epochs**: how many times we train over the full dataset.  \n  **device**: whether to run on GPU (cuda) or CPU.\n\nDefining these here ensures that tokenization, dataloaders, and model training are consistent and reproducible.\n","metadata":{}},{"cell_type":"code","source":"# Defining all important parameters in one place\nPARAMS = {\n    \"model_name\": \"bert-base-uncased\",   # pre-trained BERT model\n    \"max_len\": 256,                      # max token length for each input\n    \"batch_size\": 16,                    # batch size for DataLoader\n    \"learning_rate\": 2e-5,               # learning rate for AdamW optimizer\n    \"epochs\": 3,                         # number of training epochs\n    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"  # use GPU if available\n}\n\n\nPARAMS\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:39:24.435318Z","iopub.execute_input":"2025-10-01T05:39:24.435583Z","iopub.status.idle":"2025-10-01T05:39:24.441212Z","shell.execute_reply.started":"2025-10-01T05:39:24.435564Z","shell.execute_reply":"2025-10-01T05:39:24.440454Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'model_name': 'bert-base-uncased',\n 'max_len': 256,\n 'batch_size': 16,\n 'learning_rate': 2e-05,\n 'epochs': 3,\n 'device': 'cuda'}"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# Step 5: Tokenization.","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\n\n# Load the tokenizer for BERT\ntokenizer = BertTokenizer.from_pretrained(PARAMS[\"model_name\"])\n\n# sanity check;tokenize a single sentence\nsample_text = train_df[\"combined_text\"].iloc[0]\ntokens = tokenizer.encode_plus(\n    sample_text,\n    max_length=PARAMS[\"max_len\"],\n    padding=\"max_length\",\n    truncation=True,\n    return_tensors=\"pt\"   # return PyTorch tensors\n)\n\nprint(\"Original text:\\n\", sample_text[:200], \"...\\n\")  # first 200 chars\nprint(\"Token IDs:\\n\", tokens[\"input_ids\"])\nprint(\"Attention mask:\\n\", tokens[\"attention_mask\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:39:24.442065Z","iopub.execute_input":"2025-10-01T05:39:24.442333Z","iopub.status.idle":"2025-10-01T05:39:25.739987Z","shell.execute_reply.started":"2025-10-01T05:39:24.442304Z","shell.execute_reply":"2025-10-01T05:39:25.739212Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fef73df129b4f3f91d64e61ec6188b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85dec95508e44d18a7c1bd02fc869011"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4b08673d3c84c71b76ce447b914b1cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df09cd1733bd47fab3879d456e529b81"}},"metadata":{}},{"name":"stdout","text":"Original text:\n update busted secret service cnn april ryan called fake report trump aide firing video secret service pushed back cnn reporter claim fired trump aide physically removed white house reporting regarding ...\n\nToken IDs:\n tensor([[  101, 10651, 23142,  3595,  2326, 13229,  2258,  4575,  2170,  8275,\n          3189,  8398, 14895,  7493,  2678,  3595,  2326,  3724,  2067, 13229,\n          6398,  4366,  5045,  8398, 14895,  8186,  3718,  2317,  2160,  7316,\n          4953,  3595,  2326,  5073,  8186,  9268, 13192,  8820, 23624, 20420,\n          7096, 10625,  2317,  4580,  3375, 16542,  1057,  3595,  2326,  7800,\n          2121,  7903,  2063,  2285,  3041,  2651, 13229,  2258,  4575,  2988,\n          8398,  3447, 14895, 13192,  8820, 23624, 20420,  7096, 13127,  2317,\n          2160,  3595,  2326,  2961,  5045,  2708,  3095,  2198,  5163,  2137,\n          3923,  2557,  2897,  2317,  2160, 11370,  2258,  4575,  2409,  2466,\n         14895,  7493, 13229,  2258, 21190,  2319,  3189, 13192,  8820,  2975,\n          2317,  2160,  2236,  5163,  5458,  3689, 29364, 19752,  2292,  2113,\n          2699,  2175,  2156,  8398,  5039, 13127,  3595,  2326,  9266,  2532,\n         27838,  3981, 23564,  6820,  9266,  2532, 13229,  2285,  2187,  2100,\n          8398,  5223,  2099, 18874,  3993,  3422, 11808, 10413, 20926,  3507,\n          2304,  2450,  9467,  9061,  2611,  9061,  2196,  3421,  2451,  2204,\n          9436, 25514,  9119,  2139, 18796, 10413, 20926, 21566,  6712, 13192,\n          8820, 23624, 20420,  7096,  2317,  2160,  9266,  2532, 27838,  3981,\n         23564,  6820,  9266,  2532, 13229,  2285,  3595,  2326,  1056, 28394,\n          3064,  2117,  1056, 28394,  2102,  2165, 14674, 16215,  2099,  2711,\n          2292,  2175,  3595,  2326,  2920, 18287,  2832,  1049, 23624, 20420,\n          7096, 10625,  8620,  3375,  6624,  3043, 26709,  6593, 21466,  3265,\n         14674,  3946,  3229,  3375,  1057,  3595,  2326,  7800,  2121,  7903,\n          2063,  2285,   102,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\nAttention mask:\n tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## When we tokenized a sample, we got two main results:\n\n **Input IDs**: Each word or subword is mapped to a numeric ID from BERT’s vocabulary.  \n    The sequence starts with [CLS] (ID 101) and ends with [SEP] (ID 102).  \n    If the text is shorter than 256 tokens, the rest is padded with 0s.  \n    If longer, it is truncated to 256 tokens.  \n\n **Attention Mask**: A sequence of 1s and 0s.  \n    1 means a real token.  \n    0 means a padding token.  \n\nThis ensures that all inputs have the same length (max_len=256), and BERT can ignore padding during training.\n","metadata":{}},{"cell_type":"markdown","source":"## Step 6:  Create Pytorch dataset loaders\n\nTo prepare the data for BERT, we wrap it in a **custom PyTorch Dataset**:\n\n **NewsDataset**:  \n   Takes the cleaned text (combined_text) and labels.  \n   Uses the BERT tokenizer with our chosen `max_len=256`.  \n   Returns `input_ids`, `attention_mask`, and `labels` tensors for each sample.  \n\nWe then create **DataLoaders** for train, validation, and test sets:  \n These efficiently batch and shuffle the data.  \n Each batch contains:\n   input_ids → tokenized text  \n   attention_mask → marks real tokens vs. padding  \n   labels → 0 (FAKE) or 1 (TRUE)  \n\nThese DataLoaders will feed data into BERT during training and evaluation.\n","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\n# 1. Create a custom dataset class\nclass NewsDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = int(self.labels[idx])\n\n        # Tokenize text\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,          # [CLS] and [SEP]\n            max_length=self.max_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors=\"pt\"\n        )\n\n        return {\n            \"input_ids\": encoding[\"input_ids\"].flatten(),\n            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n            \"labels\": torch.tensor(label, dtype=torch.long)\n        }\n\n# 2. Helper function to create DataLoaders\ndef create_data_loader(df, tokenizer, max_len, batch_size):\n    ds = NewsDataset(\n        texts=df[\"combined_text\"].to_numpy(),\n        labels=df[\"label_num\"].to_numpy(),\n        tokenizer=tokenizer,\n        max_len=max_len\n    )\n\n    return DataLoader(ds, batch_size=batch_size, shuffle=True)\n\n# 3. Create DataLoaders for train, val, test\ntrain_data_loader = create_data_loader(train_df, tokenizer, PARAMS[\"max_len\"], PARAMS[\"batch_size\"])\nval_data_loader = create_data_loader(val_df, tokenizer, PARAMS[\"max_len\"], PARAMS[\"batch_size\"])\ntest_data_loader = create_data_loader(test_df, tokenizer, PARAMS[\"max_len\"], PARAMS[\"batch_size\"])\n\nlen(train_data_loader), len(val_data_loader), len(test_data_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:39:25.740946Z","iopub.execute_input":"2025-10-01T05:39:25.741305Z","iopub.status.idle":"2025-10-01T05:39:25.751252Z","shell.execute_reply.started":"2025-10-01T05:39:25.741275Z","shell.execute_reply":"2025-10-01T05:39:25.750478Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(2245, 281, 281)"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Step 7: Model Setup.\n\n\n\nIn this step, we build a custom **BERT-based classifier** for our fake news detection task.  \nThe model architecture is as follows:\n\n **BERT Base Model**: We load `bert-base-uncased` as the backbone to generate contextual embeddings from text.  \n **Dropout Layer**: Added to reduce overfitting by randomly deactivating some neurons during training.  \n **Linear Layer**: A fully connected layer that maps BERT’s hidden size (768 dimensions) to our two output classes (`FAKE` and `TRUE`).  \n  **Freezing Option**: We can choose to freeze BERT’s pre-trained layers (`freeze_bert=True`) so only the classifier head trains (faster but may underfit). If set to `False`, the entire model is fine-tuned (slower but usually yields better results).  \n **Device Placement**: The model is moved to GPU (`cuda`) if available, otherwise runs on CPU.\n\nThis classifier combines the rich semantic understanding from BERT with a lightweight classification head tailored to our dataset.\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import BertModel\n\n# Define a custom BERT-based classifier\nclass BertClassifier(nn.Module):\n    def __init__(self, freeze_bert=True):\n        super(BertClassifier, self).__init__()\n        \n        # Load pre-trained BERT model\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        \n        # Add a dropout layer for regularization\n        self.dropout = nn.Dropout(p=0.3)\n        \n        # Add a linear classifier on top (binary classification: FAKE vs TRUE)\n        self.classifier = nn.Linear(self.bert.config.hidden_size, 2)\n        \n        # Optionally freeze BERT weights (so only classifier trains)\n        if freeze_bert:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n\n    def forward(self, input_ids, attention_mask):\n        # Get BERT outputs\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        \n        # Pooled output is [CLS] token representation\n        pooled_output = outputs.pooler_output\n        \n        # Apply dropout then classifier\n        x = self.dropout(pooled_output)\n        x = self.classifier(x)\n        return x\n\n# Instantiate model\nmodel = BertClassifier(freeze_bert=False)  # set to True if you want to freeze BERT\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:39:25.752089Z","iopub.execute_input":"2025-10-01T05:39:25.752374Z","iopub.status.idle":"2025-10-01T05:39:28.651672Z","shell.execute_reply.started":"2025-10-01T05:39:25.752350Z","shell.execute_reply":"2025-10-01T05:39:28.651022Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d01385cd47e481aab0a49fb40c778c8"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"BertClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### Understanding the BERT Model Architecture\n\nWhen we print the model, we see the layers and components that make up our `BertClassifier`:\n\n1. **`bert` (the backbone)**  \n    This is the pre-trained **BERT encoder** that processes the text.  \n    It has:\n      **Embeddings**:\n        *Word embeddings*: map each token ID to a 768-dimensional vector.  \n        *Position embeddings*: capture word order in a sentence (since transformers have no sense of sequence by default).  \n        *Token type embeddings*: allow BERT to distinguish between sentence A vs sentence B (useful for tasks like QA).  \n      **Encoder layers**: 12 stacked layers (for `bert-base-uncased`).  \n        Each layer has **self-attention**, **feed-forward**, and **layer normalization**.  \n        These layers let BERT capture contextual meaning — e.g., “bank” in *river bank* vs *money bank*.  \n      **Pooler**: takes the representation of the special `[CLS]` token and transforms it into a fixed-size vector (used for classification).\n\n2. **Dropout (0.3)**  \n    A regularization layer we added to reduce overfitting.  \n    Randomly “drops” 30% of the neurons during training to make the model more robust.\n\n3. **Classifier (Linear layer)**  \n    Input: 768-dim vector from BERT (the pooled `[CLS]` token).  \n    Output: 2 logits → `[FAKE, TRUE]`.  \n    This is the final prediction layer.\n\n\n In short:  \n The **BERT encoder** extracts deep contextual features from the text.  \n The **dropout** improves generalization.  \n The **classifier** maps the features to our labels (fake vs true news).\n","metadata":{}},{"cell_type":"code","source":"# Map existing DataLoaders to the expected names\ntrain_loader = train_data_loader\nval_loader   = val_data_loader\ntest_loader  = test_data_loader\n\n# Optimizer & Loss Function Setup\n\nfrom torch.optim import AdamW\nfrom torch.nn import CrossEntropyLoss\nfrom transformers import get_linear_schedule_with_warmup\n\n# Optimizer: AdamW is the recommended optimizer for BERT\noptimizer = AdamW(model.parameters(), lr=PARAMS[\"learning_rate\"])\n\n# Scheduler: adjusts the learning rate during training\ntotal_steps = len(train_loader) * PARAMS[\"epochs\"]\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,          # warmup can be tuned\n    num_training_steps=total_steps\n)\n\n# Loss function: CrossEntropy for multi-class classification (2 classes: FAKE/TRUE)\ncriterion = CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:39:28.652554Z","iopub.execute_input":"2025-10-01T05:39:28.652837Z","iopub.status.idle":"2025-10-01T05:39:28.658909Z","shell.execute_reply.started":"2025-10-01T05:39:28.652813Z","shell.execute_reply":"2025-10-01T05:39:28.658338Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(train_loader)\nprint(optimizer)\nprint(scheduler)\nprint(criterion)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:39:28.661018Z","iopub.execute_input":"2025-10-01T05:39:28.661540Z","iopub.status.idle":"2025-10-01T05:39:28.677408Z","shell.execute_reply.started":"2025-10-01T05:39:28.661519Z","shell.execute_reply":"2025-10-01T05:39:28.676708Z"}},"outputs":[{"name":"stdout","text":"<torch.utils.data.dataloader.DataLoader object at 0x7bf45a12ded0>\nAdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    initial_lr: 2e-05\n    lr: 2e-05\n    maximize: False\n    weight_decay: 0.01\n)\n<torch.optim.lr_scheduler.LambdaLR object at 0x7bf477810d10>\nCrossEntropyLoss()\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Step 8: Training Loop.","metadata":{}},{"cell_type":"markdown","source":"This step is where the model actually **learns** from data. During training:  \n1. Batches of text + labels are fed into the model.  \n2. The model makes predictions.  \n3. A **loss** is calculated to measure errors.  \n4. Backpropagation updates the model weights to improve performance.  \n\nWe repeat this process over several **epochs** (full passes through the training set).  \nAt the end of each epoch, we track:  \n **Average loss** → how well the model is fitting.  \n **Accuracy** → how well it’s predicting.  \n\nThis step is the core of fine-tuning BERT for our dataset.  \n","metadata":{}},{"cell_type":"code","source":"# Training & Evaluation Loop\n\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\ndef train_epoch(model, data_loader, optimizer, criterion, scheduler, device):\n    model = model.train()\n    losses = []\n    correct_predictions = 0\n\n    for batch in data_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)  \n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs\n        _, preds = torch.max(logits, dim=1)\n        loss = criterion(logits, labels)\n\n        correct_predictions += torch.sum(preds == labels)\n        losses.append(loss.item())\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n\n\ndef eval_model(model, data_loader, criterion, device):\n    model = model.eval()\n    losses = []\n    correct_predictions = 0\n\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)   \n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs\n            _, preds = torch.max(logits, dim=1)\n            loss = criterion(logits, labels)\n\n            correct_predictions += torch.sum(preds == labels)\n            losses.append(loss.item())\n\n    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n\n\n# Main Training Loop\nhistory = {\"train_acc\": [], \"train_loss\": [], \"val_acc\": [], \"val_loss\": []}\n\nfor epoch in range(PARAMS[\"epochs\"]):\n    print(f\"Epoch {epoch + 1}/{PARAMS['epochs']}\")\n\n    train_acc, train_loss = train_epoch(\n        model, train_data_loader, optimizer, criterion, scheduler, device\n    )\n    val_acc, val_loss = eval_model(\n        model, val_data_loader, criterion, device\n    )\n\n    history[\"train_acc\"].append(train_acc.item())\n    history[\"train_loss\"].append(train_loss)\n    history[\"val_acc\"].append(val_acc.item())\n    history[\"val_loss\"].append(val_loss)\n\n    print(f\"Train loss {train_loss:.4f}, accuracy {train_acc:.4f}\")\n    print(f\"Val   loss {val_loss:.4f}, accuracy {val_acc:.4f}\")\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:39:28.678146Z","iopub.execute_input":"2025-10-01T05:39:28.678424Z","iopub.status.idle":"2025-10-01T07:16:04.454724Z","shell.execute_reply.started":"2025-10-01T05:39:28.678399Z","shell.execute_reply":"2025-10-01T07:16:04.453881Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\nTrain loss 0.0228, accuracy 0.9938\nVal   loss 0.0157, accuracy 0.9971\n--------------------------------------------------\nEpoch 2/3\nTrain loss 0.0051, accuracy 0.9988\nVal   loss 0.0062, accuracy 0.9982\n--------------------------------------------------\nEpoch 3/3\nTrain loss 0.0014, accuracy 0.9997\nVal   loss 0.0095, accuracy 0.9982\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### Training Epoch Outputs\n\nEach epoch output shows the model's performance on both the training and validation sets:  \n\n **Train loss / accuracy**: How well the model is fitting the training data. A decreasing loss and increasing accuracy indicate learning.  \n **Validation loss / accuracy**: How well the model generalizes to unseen data. Stable or slightly higher validation loss compared to training is normal.  \n **Epoch progression**: Each epoch represents a full pass through the training dataset.  \n\nFrom the outputs, the model quickly learned to distinguish FAKE and TRUE news, achieving very high accuracy and low loss by the final epoch.\n","metadata":{}},{"cell_type":"markdown","source":"## Step 9: Evaluation.","metadata":{}},{"cell_type":"markdown","source":"## Model Evaluation on the Test Set\n\nNow that our BERT model has been trained for 3 epochs, we need to evaluate its performance on the test set.  \nThis involves:\n Switching the model to **evaluation mode** (disables dropout, gradient updates).  \n Running the model on the test dataloader.  \n Collecting predictions and true labels.  \n Computing evaluation metrics:\n   **Accuracy** (overall correctness).  \n   **Precision, Recall, F1-score** (per-class and averaged).  \n   **Confusion Matrix** (to see where the model makes mistakes).  \n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in test_data_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Forward pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n        # HuggingFace model returns logits directly\n        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs\n        preds = torch.argmax(logits, dim=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Accuracy\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"Test Accuracy: {acc:.4f}\")\n\n# Detailed metrics\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=[\"FAKE\", \"TRUE\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T08:01:07.009224Z","iopub.execute_input":"2025-10-01T08:01:07.009685Z","iopub.status.idle":"2025-10-01T08:02:36.345716Z","shell.execute_reply.started":"2025-10-01T08:01:07.009662Z","shell.execute_reply":"2025-10-01T08:02:36.344911Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9996\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        FAKE       1.00      1.00      1.00      2348\n        TRUE       1.00      1.00      1.00      2142\n\n    accuracy                           1.00      4490\n   macro avg       1.00      1.00      1.00      4490\nweighted avg       1.00      1.00      1.00      4490\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"###  Evaluation Results on Test Set\n\nThe model achieved outstanding performance on the test set:\n\n **Accuracy:** 99.96%  \n **Precision, Recall, and F1-score:** All values are essentially 1.00 (100%) for both classes (FAKE and TRUE).  \nThe test set contained 2,348 FAKE and 2,142 TRUE examples, meaning the dataset is relatively balanced.  \n\n####  Interpretation\nThe model is almost perfectly distinguishing between FAKE and TRUE news articles.  \n An accuracy of 99.96% suggests that only about **2 samples out of 4,490** were misclassified.  \n High precision and recall indicate that the model is not only making correct predictions but also covering nearly all true cases.  \n\n####  Conclusion\nThese results show that the fine-tuned BERT model generalizes very well on unseen data. However, to further validate performance and identify the few errors made, we will proceed with **visualization (confusion matrix)** and **error analysis**.\n","metadata":{}},{"cell_type":"markdown","source":"## Confusion Matrix.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n# Compute confusion matrix\ncm = confusion_matrix(all_labels, all_preds)\n\n# Plot heatmap\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"FAKE\", \"TRUE\"], yticklabels=[\"FAKE\", \"TRUE\"])\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T08:18:34.063697Z","iopub.execute_input":"2025-10-01T08:18:34.063970Z","iopub.status.idle":"2025-10-01T08:18:34.456621Z","shell.execute_reply.started":"2025-10-01T08:18:34.063948Z","shell.execute_reply":"2025-10-01T08:18:34.455954Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"###  Confusion Matrix Analysis\n\nThe confusion matrix summarizes how well the model classified FAKE vs TRUE news articles:\n\n  **Top-left (2347):** FAKE articles correctly predicted as FAKE.  \n  **Bottom-right (2141):** TRUE articles correctly predicted as TRUE.  \n  **Top-right (1):** FAKE article incorrectly predicted as TRUE (false negative).  \n  **Bottom-left (1):** TRUE article incorrectly predicted as FAKE (false positive).  \n\n####  Interpretation\nOut of **4,490 test samples**, only **2 were misclassified**:\n    1 FAKE mislabeled as TRUE.  \n    1 TRUE mislabeled as FAKE.  \n  This explains the near-perfect **99.96% accuracy**.  \n  The model shows **no systematic bias** toward one class — both FAKE and TRUE are classified with equal reliability.\n\n#### Conclusion\nThe confusion matrix confirms that the model is **highly reliable** in distinguishing between FAKE and TRUE news, with only negligible errors.\n","metadata":{}},{"cell_type":"markdown","source":"## Classification Report Visualization.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report\n\n# Get classification report as dictionary\nreport = classification_report(all_labels, all_preds, target_names=[\"FAKE\", \"TRUE\"], output_dict=True)\n\n# Convert to DataFrame for plotting\ndf_report = pd.DataFrame(report).transpose().iloc[:2, :3]  # only FAKE & TRUE rows, precision/recall/f1\n\n# Plot\nplt.figure(figsize=(8, 5))\ndf_report.plot(kind=\"bar\", figsize=(8,5), ylim=(0.9, 1.05), colormap=\"viridis\")\n\nplt.title(\"Precision, Recall, and F1-score per Class\")\nplt.ylabel(\"Score\")\nplt.xticks(rotation=0)\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T08:27:04.481895Z","iopub.execute_input":"2025-10-01T08:27:04.482814Z","iopub.status.idle":"2025-10-01T08:27:04.706049Z","shell.execute_reply.started":"2025-10-01T08:27:04.482787Z","shell.execute_reply":"2025-10-01T08:27:04.705352Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"###  Precision, Recall, and F1-score Visualization\n\nThe bar chart provides a visual summary of the model’s performance on the test set:\n\n  **FAKE class:** Precision, recall, and F1-score are all at **1.00**, meaning the model nearly perfectly identifies FAKE articles.  \n  **TRUE class:** Precision, recall, and F1-score are also at **1.00**, showing the same near-perfect performance.  \n\n####  Interpretation\n  The model demonstrates **balanced performance** across both classes.  \n  There is **no trade-off** between precision and recall — the model is both highly accurate in its predictions and comprehensive in capturing all true cases.  \n  This visualization confirms what the classification report and confusion matrix showed earlier: the model generalizes extremely well.\n\n#### Conclusion\n The model achieves **state-of-the-art-level results** on this dataset, making only 2 errors out of 4,490 samples. Next, we will perform **error analysis** to inspect these misclassified cases more closely.\n","metadata":{}},{"cell_type":"markdown","source":"## Error Analysis: Extracting Misclassified Samples.","metadata":{}},{"cell_type":"code","source":"# Converting  predictions and labels into arrays\nall_preds = np.array(all_preds)\nall_labels = np.array(all_labels)\n\n# Find misclassified indices\nmisclassified_idx = np.where(all_preds != all_labels)[0]\n\nprint(f\"Number of misclassified samples: {len(misclassified_idx)}\")\n\n# Show a few misclassified samples from test_df\nfor idx in misclassified_idx:\n    true_label = \"FAKE\" if all_labels[idx] == 0 else \"TRUE\"\n    pred_label = \"FAKE\" if all_preds[idx] == 0 else \"TRUE\"\n    print(f\"\\nSample {idx}:\")\n    print(f\"True Label: {true_label}, Predicted Label: {pred_label}\")\n    print(f\"Text: {test_df.iloc[idx]['text'][:500]}...\")  # show first 500 chars for readability\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T08:32:09.988882Z","iopub.execute_input":"2025-10-01T08:32:09.989577Z","iopub.status.idle":"2025-10-01T08:32:09.994792Z","shell.execute_reply.started":"2025-10-01T08:32:09.989553Z","shell.execute_reply":"2025-10-01T08:32:09.994073Z"}},"outputs":[{"name":"stdout","text":"Number of misclassified samples: 2\n\nSample 487:\nTrue Label: TRUE, Predicted Label: FAKE\nText: WASHINGTON (Reuters) - U.S. Senate Leader McConnell said he expects to move on legislation to repeal and replace Obamacare as soon as his there are enough votes to pass the Republican-controlled chamber. The Kentucky Republican, speaking to reporters at a news conference, added that he does not expect to get much initial cooperation from Democrats, whose votes Republicans need to gain the 60 needed to pass bills. ...\n\nSample 4111:\nTrue Label: FAKE, Predicted Label: TRUE\nText: BEIRUT (Reuters) - Lebanon s cabinet will meet on Tuesday for the first time since the country entered a political crisis a month ago when Prime Minister Saad al-Hariri offered his resignation in a broadcast from Saudi Arabia.  The cabinet s media office said the session would begin at noon at the presidential palace. The meeting is expected to address Hariri s resignation which thrust Lebanon back into a regional tussle between Riyadh and its main regional foe, Iran. ...\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"### Error Analysis Results\n\nThe model made only **2 misclassifications out of 4,490 test samples**:\n\n1. **Sample 487**  \n     **True Label:** TRUE  \n     **Predicted Label:** FAKE  \n     **Text Snippet:** News about U.S. Senate Leader McConnell on Obamacare legislation.  \n     **Possible Reason:** This is a straightforward political news report. The misclassification could be due to overlapping patterns in the dataset where political news sometimes appears in both FAKE and TRUE categories.  \n\n2. **Sample 4111**  \n     **True Label:** FAKE  \n     **Predicted Label:** TRUE  \n     **Text Snippet:** Report about Lebanon’s cabinet meeting after a political crisis.  \n     **Possible Reason:** The article has a very formal reporting style (Reuters-like), which might resemble legitimate news sources. The model likely confused the stylistic cues with true reporting.\n\n####  Interpretation\n  Both errors occurred in **political news content**, which can be difficult to distinguish since FAKE and TRUE political news often share similar language and tone.  \n  The mistakes are **reasonable**: the texts look like standard journalistic reporting, making them inherently harder to classify.  \n  This may also reflect potential **labeling noise** in the dataset, where some FAKE/TRUE labels could be debatable.\n\n####  Conclusion\nThe model is highly reliable (99.96% accuracy), and the **few misclassifications are explainable**. These results confirm that the BERT model generalizes extremely well, with only marginal limitations in ambiguous cases.\n","metadata":{}},{"cell_type":"markdown","source":"# Step 10: Save Custom Bert Classifier Model and Tokenizer.  ","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\n\n# Moving the model to CPU before saving \nmodel.to(\"cpu\")\n\n# Define save directory\nsave_dir = \"saved_bert_model\"\nos.makedirs(save_dir, exist_ok=True)\n\n# Save model weights (state_dict) with torch\ntorch.save(model.state_dict(), os.path.join(save_dir, \"bert_classifier_weights.pth\"))\n\n# Save tokenizer using Hugging Face\ntokenizer.save_pretrained(save_dir)\n\nprint(f\" Custom model weights and tokenizer saved successfully to: {save_dir}/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T09:00:29.725368Z","iopub.execute_input":"2025-10-01T09:00:29.725908Z","iopub.status.idle":"2025-10-01T09:00:30.674794Z","shell.execute_reply.started":"2025-10-01T09:00:29.725885Z","shell.execute_reply":"2025-10-01T09:00:30.673995Z"}},"outputs":[{"name":"stdout","text":" Custom model weights and tokenizer saved successfully to: saved_bert_model/\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"\n# LOAD CUSTOM BERT CLASSIFIER MODEL & TOKENIZER\n\n# Rebuild the same model architecture first\nmodel = BertClassifier(n_classes=2)   # same number of classes as before\nmodel.load_state_dict(torch.load(\"saved_bert_model/bert_classifier_weights.pth\"))\nmodel.to(device)\nmodel.eval()\n\n# Reload tokenizer\nfrom transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained(\"saved_bert_model\")\n\nprint(\"Model and tokenizer loaded successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Zip the saved model folder\nshutil.make_archive(\"saved_bert_model\", 'zip', \"saved_bert_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T09:10:32.192060Z","iopub.execute_input":"2025-10-01T09:10:32.192368Z","iopub.status.idle":"2025-10-01T09:10:54.091767Z","shell.execute_reply.started":"2025-10-01T09:10:32.192345Z","shell.execute_reply":"2025-10-01T09:10:54.091151Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/saved_bert_model.zip'"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"# Step 11: Make Predictions on New Text.\n\nThis is to ensure our model can generalize beyond the training and test datasets, we will create a helper function.  \nThis function will take in raw text, tokenize it, pass it through our trained BERT classifier, and return the predicted label (`FAKE` or `TRUE`) along with the probabilities for each class.\n","metadata":{}},{"cell_type":"markdown","source":"Now we will test the function on some example sentences that were not part of the dataset.  \nThis will demonstrate how the model can classify arbitrary news statements into **FAKE** or **TRUE**.\n","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Step 1: Set device automatically\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Step 2: Define a prediction function\ndef predict_text(model, tokenizer, text, device, max_len=256):\n    \"\"\"\n    Predicts the label of a single text using a BERT model.\n\n    Args:\n        model: Trained BERT model\n        tokenizer: HuggingFace tokenizer\n        text (str): Text to classify\n        device: 'cuda' or 'cpu'\n        max_len (int): Max sequence length for BERT\n\n    Returns:\n        label (str): \"FAKE\" or \"TRUE\"\n        probs (np.array): Probability for each class\n    \"\"\"\n    # Tokenize input\n    encoding = tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=max_len,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n\n    # Move inputs to same device as model\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n\n    # Make sure model is on the same device\n    model.to(device)\n    model.eval()\n\n    # Run prediction\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs if isinstance(outputs, torch.Tensor) else outputs.logits\n        probs = torch.softmax(logits, dim=1)\n\n    # Get predicted class\n    pred = torch.argmax(probs, dim=1).cpu().item()\n    label = \"FAKE\" if pred == 0 else \"TRUE\"\n\n    return label, probs.cpu().numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T09:42:22.220703Z","iopub.execute_input":"2025-10-01T09:42:22.220972Z","iopub.status.idle":"2025-10-01T09:42:22.229007Z","shell.execute_reply.started":"2025-10-01T09:42:22.220952Z","shell.execute_reply":"2025-10-01T09:42:22.228290Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Running predictions on text\nsample_texts = [  # <-- keep the same variable name to avoid confusion\n    \"Donald Trump has been appointed CEO of Microsoft.\"\n]\n\nfor text in sample_texts: \n    label, probs = predict_text(model, tokenizer, text, device)\n    print(f\"Text: {text}\")\n    print(f\"Predicted Label: {label}\")\n    print(f\"Probabilities: {probs}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T09:47:50.859709Z","iopub.execute_input":"2025-10-01T09:47:50.860285Z","iopub.status.idle":"2025-10-01T09:47:50.893605Z","shell.execute_reply.started":"2025-10-01T09:47:50.860258Z","shell.execute_reply":"2025-10-01T09:47:50.892847Z"}},"outputs":[{"name":"stdout","text":"Text: Donald Trump has been appointed CEO of Microsoft.\nPredicted Label: FAKE\nProbabilities: [[0.73583615 0.26416385]]\n\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"### Conclusion\n\nWhen tested with the statement **\"Donald Trump has been appointed CEO of Microsoft,\"** the model predicted **FAKE** with a confidence of **73.6%**. This demonstrates the model’s ability to detect fabricated news and provide probability scores that reflect its certainty, showing its effectiveness as a tool for supporting fact-checking and identifying misleading information.\n","metadata":{}},{"cell_type":"code","source":"model.to(\"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T09:58:04.967301Z","iopub.execute_input":"2025-10-01T09:58:04.968010Z","iopub.status.idle":"2025-10-01T09:58:05.159923Z","shell.execute_reply.started":"2025-10-01T09:58:04.967984Z","shell.execute_reply":"2025-10-01T09:58:05.159228Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"BertClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"# Checking if model parameters are on CPU\nnext(model.parameters()).device\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T09:59:03.290667Z","iopub.execute_input":"2025-10-01T09:59:03.290910Z","iopub.status.idle":"2025-10-01T09:59:03.295722Z","shell.execute_reply.started":"2025-10-01T09:59:03.290893Z","shell.execute_reply":"2025-10-01T09:59:03.294979Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}],"execution_count":46}]}